# -*- coding: utf-8 -*-
"""Lung_Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1piE-eHC6T6GuLAN3ZxKJTnZciUfuB_22
"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import random

mainpath = '/content/drive/MyDrive/Lung_Disease/'
datadir = os.path.join(mainpath,'data')
csvpath = os.path.join(mainpath,'preprocessed_data.csv')

print(f'Image Data : {datadir}')
print(f'CSV file : {csvpath}')

import tensorflow as tf
print(f'TensorFlow Version : {tf.__version__}')

feature_map = {
    'image': tf.io.FixedLenFeature([], tf.string),
    'image_id': tf.io.FixedLenFeature([], tf.string),
    'No Finding': tf.io.FixedLenFeature([], tf.int64),
    'Atelectasis': tf.io.FixedLenFeature([], tf.int64),
    'Consolidation': tf.io.FixedLenFeature([], tf.int64),
    'Infiltration': tf.io.FixedLenFeature([], tf.int64),
    'Pneumothorax': tf.io.FixedLenFeature([], tf.int64),
    'Edema': tf.io.FixedLenFeature([], tf.int64),
    'Emphysema': tf.io.FixedLenFeature([], tf.int64),
    'Fibrosis': tf.io.FixedLenFeature([], tf.int64),
    'Effusion': tf.io.FixedLenFeature([], tf.int64),
    'Pneumonia': tf.io.FixedLenFeature([], tf.int64),
    'Pleural_Thickening': tf.io.FixedLenFeature([], tf.int64),
    'Cardiomegaly': tf.io.FixedLenFeature([], tf.int64),
    'Nodule': tf.io.FixedLenFeature([], tf.int64),
    'Mass': tf.io.FixedLenFeature([], tf.int64),
    'Hernia': tf.io.FixedLenFeature([], tf.int64)
}

def tfr_decoder(path, shuffle=True):
    def image_decoder(data):
        example = tf.io.parse_single_example(data, feature_map)
        image = example['image']
        image = tf.io.decode_image(image, channels=3)
        image = tf.image.convert_image_dtype(image, tf.float32)
        image = tf.image.resize_with_pad(image, 150, 150)
        image.set_shape([150,150,3])
        image = image/255.

        print([label for label in sorted(list(example.keys())) if label!='image' and label!='image_id'])
        labels = [tf.cast(example[x], tf.float32) for x in sorted(list(example.keys())) if x!='image_id' and x!='image']

        return image, labels

    data_li = [os.path.join(datadir,x) for x in os.listdir(path)]
    # Randomly sample files from data_list
    reduced_size = int(len(data_li) * 0.6)
    data_list = random.sample(data_li, reduced_size)

    split = int(len(data_list)*0.8)
    train_data, val_data = data_list[:split], data_list[split:]

    trainds = tf.data.TFRecordDataset(train_data)
    trainds = trainds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)

    valds = tf.data.TFRecordDataset(val_data)
    valds = valds.map(image_decoder, num_parallel_calls=tf.data.experimental.AUTOTUNE)

    if shuffle:
        trainds = trainds.shuffle(1024)

    trainds = trainds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)
    valds = valds.batch(128).prefetch(tf.data.experimental.AUTOTUNE)
    return trainds, valds

trainds, valds = tfr_decoder(datadir)
print(trainds)

effic = tf.keras.applications.EfficientNetB2(
    include_top=False, weights=None,input_shape=(150,150,3), pooling='avg')

incep = tf.keras.applications.InceptionV3(
    include_top=False, weights=None, input_shape=(150,150,3), pooling='avg')

model = tf.keras.Sequential([
            effic,
            tf.keras.layers.Dense(512, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(15, activation='sigmoid'),
])

model.compile(loss='binary_crossentropy',
             optimizer='Adam',
             metrics=[tf.keras.metrics.AUC(multi_label=True),'binary_accuracy'])

model.summary()

model.fit(trainds, epochs=3,steps_per_epoch = 120,batch_size=32)
model.evaluate(valds)

forecast = model.predict(valds)

result = model.evaluate(valds)

loss = result[0]
accuracy = result[1]
auc = result[2]

# Print the results
print(f'Validation Loss: {loss}')
print(f'Validation AUC: {accuracy}')
print(f'Validation accuracy: {auc}')

model.save('lungs_disease_model.h5')
model.save('kerasModel_lungs_diseases')
# Download the model file

from google.colab import files
# files.download('lungs_disease_model.h5')
files.download('lungs_disease_model.h5')

!zip -r /content/kerasfile.zip /content/kerasModel_lungs_diseases

files.download('kerasfile.zip')

from tensorflow.keras.preprocessing import image

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

def preprocess_image(img_path, target_size=(150, 150)):
    # Load the image
    img = image.load_img(img_path)
    # Convert the image to an array
    img_array = image.img_to_array(img)
    # Convert image dtype to float32
    img_array = tf.image.convert_image_dtype(img_array, tf.float32)
    # Resize with padding to target size
    img_array = tf.image.resize_with_pad(img_array, target_size[0], target_size[1])
    # Ensure the shape is set correctly
    img_array.set_shape([target_size[0], target_size[1], 3])
    # Normalize the image
    img_array = img_array / 255.0
    # Expand the dimensions to match the input format (batch size, height, width, channels)
    img_array = np.expand_dims(img_array, axis=0)
    return img_array

# Path to the image you want to predict
img_path = '/content/lung_image.jpg'

# Preprocess the image
preprocessed_img = preprocess_image(img_path)

# Print preprocessed image array to verify
print("Preprocessed image array shape:", preprocessed_img.shape)

disease_names = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema',
                 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule',
                 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']
# Preprocess the image
preprocessed_img = preprocess_image(img_path)

# Make predictions
predictions = model.predict(preprocessed_img)

# Get the predicted probabilities for each class
predicted_probabilities = predictions[0]

# Print the predictions
for disease, probability in zip(disease_names, predicted_probabilities):
    print(f"{disease}: {probability:.4f}")



